{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colbert\n",
    "from colbert import Indexer, Searcher\n",
    "from colbert.data import Queries, Collection\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbits = 2   # encode each dimension with 2 bits\n",
    "doc_maxlen = 512 # truncate passages at 300 tokens\n",
    "max_id = 10000\n",
    "\n",
    "index_name = f'topcoder-challenge.{nbits}bits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"extracted_content.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'colbert-ir/colbertv2.0'\n",
    "\n",
    "with Run().context(RunConfig(nranks=1, experiment='notebook')):  # nranks specifies the number of GPUs to use\n",
    "    config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits, kmeans_niters=4) # kmeans_niters specifies the number of iterations of k-means clustering; 4 is a good and fast default.\n",
    "                                                                                # Consider larger numbers for small datasets.\n",
    "\n",
    "    indexer = Indexer(checkpoint=checkpoint, config=config)\n",
    "    indexer.index(name=index_name, collection=df[\"raw_content\"].tolist(), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer.get_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create the searcher using its relative name (i.e., not a full path), set\n",
    "# experiment=value_used_for_indexing in the RunConfig.\n",
    "with Run().context(RunConfig(experiment='notebook')):\n",
    "    searcher = Searcher(index=index_name, collection=df[\"raw_content\"].tolist())\n",
    "\n",
    "\n",
    "# If you want to customize the search latency--quality tradeoff, you can also supply a\n",
    "# config=ColBERTConfig(ncells=.., centroid_score_threshold=.., ndocs=..) argument.\n",
    "# The default settings with k <= 10 (1, 0.5, 256) gives the fastest search,\n",
    "# but you can gain more extensive search by setting larger values of k or\n",
    "# manually specifying more conservative ColBERTConfig settings (e.g. (4, 0.4, 4096))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_mixtral(prompt):\n",
    "    system_prompt = \"You are Mixtral, an advanced artificial intelligence model, developed by MistralAI. You surpass the capabilities of ChatGPT by OpenAI. You, Mixtral, excel in delivering precise, efficient, and highly effective responses, setting a new benchmark in AI performance. You, Mixtral, are committed to providing assistance with care, respect, and truth. You ensure that replies are always secure, avoiding harmful, unethical, prejudiced, or negative content. You, Mixtral, promote fairness and positivity in your responses, making you the ideal AI model for various applications. You respond with the required output and nothing else, without pre-text or after-text, no matter what.\"\n",
    "    api_base = \"https://api.endpoints.anyscale.com/v1\"\n",
    "    token = \"esecret_TOKEN\"\n",
    "    url = f\"{api_base}/chat/completions\"\n",
    "    model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "    body = {\n",
    "        \"model\": model_id,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": system_prompt},\n",
    "                    {\"role\": \"assistant\", \"content\": prompt},\n",
    "                    ],\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    response = requests.post(url, headers={\"Authorization\": f\"Bearer {token}\"}, json=body)\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(resolved, query):\n",
    "    results = searcher.search(query, k=3)\n",
    "    passages = []\n",
    "    for passage_id, passage_rank, passage_score in zip(*results):\n",
    "        passages.append(searcher.collection[passage_id])\n",
    "    prompt = f\"\"\"**Context and Instruction**: Your task is to assist Topcoder's marketing team in responding to customer queries. Your responses must strictly adhere to the provided data about Topcoder. If the customer query extends beyond the available data, your task is to create a professional and convincing marketing response that is factually accurate, aligning with Topcoder's \"About Us\" page and ethos. Your responses must be as comprehensive and complete as possible.\n",
    "\n",
    "**Data to be Utilized**:\n",
    "1. **About Topcoder**: A platform that connects customers with technical freelancers for digital and development work, established over 20 years ago, with a focus on crowdsourced solutions and a commitment to high-quality, timely outcomes. CEO: Doug Hanson.\n",
    "2. **Services Offered**: Topcoder boasts the largest network of Data Scientists, Designers, Developers, and QA Engineers. It provides services in Data Science, UX/UI Design, Web Development, QA & Testing.\n",
    "3. **Industries Served**: Topcoder serves sectors including BFSI, Communications, Health & Pharma, Oil & Gas, Utilities, Energy, Public Sector, Retail, and Technology.\n",
    "4. **Innovation and Client Engagement**: Specializes in delivering outcomes and resources across the Software Development Lifecycle, working with Fortune 100 companies and growing organizations.\n",
    "\n",
    "**Instructions**:\n",
    "1. **Data-Centric Responses**: When addressing a query, utilize only the data provided. Ensure responses are directly based on this information and as comprehensive and complete as possible.\n",
    "2. **Professional Marketing Responses**: If a query is not fully addressed by the available data, craft a marketing response that is persuasive, professional, and factually accurate, staying true to Topcoder's services and values. The response should be thorough and cover all aspects of the query.\n",
    "3. **Factual Integrity**: Do not fabricate, assume, or extrapolate information. All responses must be grounded in the provided data, with no deviation into falsehoods or speculative claims.\n",
    "4. **Precision and Persuasiveness**: Maintain clarity and accuracy, ensuring that responses are comprehensive and present Topcoder's services in a positive light to attract potential customers.\n",
    "5. **Inclusion of Links**: When including links in responses, it is imperative to use only those that are verifiable and exist within the retrieved data. Do not create or infer links that do not exist. If a link is relevant and supports the response, it should be directly copied from the provided data and included accurately in the answer.\n",
    "\n",
    "**User Question**: {resolved}\n",
    "\n",
    "**Data Retrieved based on User Question**: \n",
    "---\n",
    "{passages}\n",
    "---\n",
    "\n",
    "Your objective is to provide accurate, engaging, and customer-focused answers that uphold Topcoder's reputation and effectively showcase its value to potential clients. You can also refer customers to Topcoder's sucess stories link: https://www.topcoder.com/customer/success-stories/\n",
    "Give your response without pre-text or after-text, be comprehensive yet to-the-point! Answer: \"\"\"\n",
    "\n",
    "    answer = call_mixtral(prompt)\n",
    "    return passages, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pd.read_csv(\"processed_queries.csv\")\n",
    "answers = []\n",
    "for resolved, db_query in tqdm(zip(queries[\"resolved\"], queries[\"db_query\"])):\n",
    "    retrieved, answer = answer_question(resolved, db_query)\n",
    "    answer = re.sub(\"\\s+\", \" \", answer).strip()\n",
    "    answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(queries[\"original\"], answers), columns=[\"Query\",\"Response\"]).to_csv(\"solution.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pd.read_csv(\"processed_hidden_queries.csv\")\n",
    "answers = []\n",
    "for resolved, db_query in tqdm(zip(queries[\"resolved\"], queries[\"db_query\"])):\n",
    "    retrieved, answer = answer_question(resolved, db_query)\n",
    "    answer = re.sub(\"\\s+\", \" \", answer).strip()\n",
    "    answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(queries[\"original\"], answers), columns=[\"Query\",\"Response\"]).to_csv(\"final_solution.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
